{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127a9887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c86894bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the dataset in characters: 1115394\n"
     ]
    }
   ],
   "source": [
    "with open(\"input.txt\", 'r', encoding='utf-8') as f:\n",
    "    text: Final[str] = f.read()\n",
    "\n",
    "print(f\"length of the dataset in characters: {len(text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a14652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c66627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size: 65\n"
     ]
    }
   ],
   "source": [
    "# Get the character set.\n",
    "chars: Final[list[str]] = sorted(list(set(text)))\n",
    "vocab_size: Final[int] = len(chars)\n",
    "print(f\"vocab: {''.join(chars)}\")\n",
    "print(f\"vocab size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6075d44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42, 2]\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "stoi: Final[dict[str, int]] = {ch: i for i, ch in enumerate(chars)}\n",
    "itos: Final[dict[int, str]] = {i: ch for ch, i in stoi.items()}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode(\"Hello World!\"))\n",
    "print(decode(encode(\"Hello World!\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234dc83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device: Final[str] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data: Final[torch.Tensor] = torch.tensor(encode(text), dtype=torch.long).to(device)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090a9b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training data: 1003854\n",
      "length of validation data: 111540\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and validation sets.\n",
    "\n",
    "n: Final[int] = int(0.9 * len(data))\n",
    "train_data: Final[torch.Tensor] = data[:n]\n",
    "val_data: Final[torch.Tensor] = data[n:]\n",
    "print(f\"length of training data: {len(train_data)}\")\n",
    "print(f\"length of validation data: {len(val_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "255f503e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size: Final[int] = 8\n",
    "train_data[:block_size + 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b64c3244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([18], device='cuda:0') target: 47\n",
      "input: tensor([18, 47], device='cuda:0') target: 56\n",
      "input: tensor([18, 47, 56], device='cuda:0') target: 57\n",
      "input: tensor([18, 47, 56, 57], device='cuda:0') target: 58\n",
      "input: tensor([18, 47, 56, 57, 58], device='cuda:0') target: 1\n",
      "input: tensor([18, 47, 56, 57, 58,  1], device='cuda:0') target: 15\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15], device='cuda:0') target: 47\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15, 47], device='cuda:0') target: 58\n"
     ]
    }
   ],
   "source": [
    "x: Final[torch.Tensor] = train_data[:block_size]\n",
    "y: Final[torch.Tensor] = train_data[1:block_size + 1]\n",
    "for i in range(block_size):\n",
    "    context = x[:i + 1]\n",
    "    target = y[i]\n",
    "    print(f\"input: {context} target: {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb023eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "batch_size: Final[int] = 4 # how many independent sequences will we process in parallel?\n",
    "block_size: Final[int] = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    data: Final[torch.Tensor] = train_data if split == \"train\" else val_data\n",
    "    ix: Final[torch.Tensor] = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x: Final[torch.Tensor] = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y: Final[torch.Tensor] = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1729349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:  torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]], device='cuda:0')\n",
      "Targets:  torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch(\"train\")\n",
    "print(\"Inputs: \", xb.shape)\n",
    "print(xb)\n",
    "print(\"Targets: \", yb.shape)\n",
    "print(yb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "928a8e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([24], device='cuda:0') target: 43\n",
      "input: tensor([24, 43], device='cuda:0') target: 58\n",
      "input: tensor([24, 43, 58], device='cuda:0') target: 5\n",
      "input: tensor([24, 43, 58,  5], device='cuda:0') target: 57\n",
      "input: tensor([24, 43, 58,  5, 57], device='cuda:0') target: 1\n",
      "input: tensor([24, 43, 58,  5, 57,  1], device='cuda:0') target: 46\n",
      "input: tensor([24, 43, 58,  5, 57,  1, 46], device='cuda:0') target: 43\n",
      "input: tensor([24, 43, 58,  5, 57,  1, 46, 43], device='cuda:0') target: 39\n",
      "input: tensor([44], device='cuda:0') target: 53\n",
      "input: tensor([44, 53], device='cuda:0') target: 56\n",
      "input: tensor([44, 53, 56], device='cuda:0') target: 1\n",
      "input: tensor([44, 53, 56,  1], device='cuda:0') target: 58\n",
      "input: tensor([44, 53, 56,  1, 58], device='cuda:0') target: 46\n",
      "input: tensor([44, 53, 56,  1, 58, 46], device='cuda:0') target: 39\n",
      "input: tensor([44, 53, 56,  1, 58, 46, 39], device='cuda:0') target: 58\n",
      "input: tensor([44, 53, 56,  1, 58, 46, 39, 58], device='cuda:0') target: 1\n",
      "input: tensor([52], device='cuda:0') target: 58\n",
      "input: tensor([52, 58], device='cuda:0') target: 1\n",
      "input: tensor([52, 58,  1], device='cuda:0') target: 58\n",
      "input: tensor([52, 58,  1, 58], device='cuda:0') target: 46\n",
      "input: tensor([52, 58,  1, 58, 46], device='cuda:0') target: 39\n",
      "input: tensor([52, 58,  1, 58, 46, 39], device='cuda:0') target: 58\n",
      "input: tensor([52, 58,  1, 58, 46, 39, 58], device='cuda:0') target: 1\n",
      "input: tensor([52, 58,  1, 58, 46, 39, 58,  1], device='cuda:0') target: 46\n",
      "input: tensor([25], device='cuda:0') target: 17\n",
      "input: tensor([25, 17], device='cuda:0') target: 27\n",
      "input: tensor([25, 17, 27], device='cuda:0') target: 10\n",
      "input: tensor([25, 17, 27, 10], device='cuda:0') target: 0\n",
      "input: tensor([25, 17, 27, 10,  0], device='cuda:0') target: 21\n",
      "input: tensor([25, 17, 27, 10,  0, 21], device='cuda:0') target: 1\n",
      "input: tensor([25, 17, 27, 10,  0, 21,  1], device='cuda:0') target: 54\n",
      "input: tensor([25, 17, 27, 10,  0, 21,  1, 54], device='cuda:0') target: 39\n"
     ]
    }
   ],
   "source": [
    "for b_idx in range(batch_size): # for each batch\n",
    "    for t in range(block_size): # for each time dimension\n",
    "        context = xb[b_idx, :t + 1]\n",
    "        target = yb[b_idx, t]\n",
    "        print(f\"input: {context} target: {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3373eb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "pYCXxfRkRZd\n",
      "wc'wfNfT;OLlTEeC K\n",
      "jxqPToTb?bXAUG:C-SGJO-33SM:C?YI3a\n",
      "hs:LVXJFhXeNuwqhObxZ.tSVrddXlaSZaNe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table: Final[nn.Embedding] = nn.Embedding(\n",
    "            vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx: torch.Tensor, target: torch.Tensor | None = None\n",
    "        )-> Tuple[torch.Tensor, torch.Tensor | None]:\n",
    "\n",
    "        # idx and target are both (batch_size, block_size) tensors\n",
    "        # logits: (batch_size, block_size, vocab_size)\n",
    "        logits: Final[torch.Tensor] = self.token_embedding_table(idx)\n",
    "\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # (batch_size, block_size, vocab_size) -> (batch_size * block_size, vocab_size)\n",
    "            B, T, C = logits.shape\n",
    "            logits: Final[torch.Tensor] = logits.view(B * T, C)\n",
    "            # (batch_size, block_size) -> (batch_size * block_size)\n",
    "            target = target.view(B * T)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx: torch.Tensor, max_new_tokens: int) -> torch.Tensor:\n",
    "        # idx is (B, T) tensor\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, _ = self(idx)\n",
    "            # focus on the last time step\n",
    "            logits = logits[:, -1, :] # (B, C)\n",
    "            # Apply softmax to get probabilities\n",
    "            # Apply softmax to vocab_size dimension\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T + 1)\n",
    "        return idx\n",
    "\n",
    "model: Final[BigramLanguageModel] = BigramLanguageModel(vocab_size).to(device)\n",
    "logits, loss = model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "# New line character is 0, which is a perfect start sequence for the model.\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "out_idx = model.generate(idx, 100)[0].tolist() # use [0] to get the first batch.\n",
    "print(decode(out_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efc5562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer: torch.optim.AdamW = torch.optim.AdamW(\n",
    "    model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b330a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.394822835922241\n"
     ]
    }
   ],
   "source": [
    "batch_size: int = 32\n",
    "max_steps: int = 10000\n",
    "\n",
    "loss = None\n",
    "\n",
    "for step in range(max_steps):\n",
    "    # Sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # Forward pass\n",
    "    logits, loss = model(xb, yb)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "assert loss is not None\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cd23239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wawice my.\n",
      "\n",
      "HDERarom oroup\n",
      "Yowh$Frtof isth ble mil ndill, ath iree sengmin lat Heriliovets, and Win nghir.\n",
      "Tranousel lind me l.\n",
      "HAule ce hiry:\n",
      "Supr aisspllw y.\n",
      "Herindu n Boopetelaves\n",
      "MP:\n",
      "\n",
      "Pl, d mothakleo Windo whth eisbyo the m dourive we higend t so mower; te\n",
      "\n",
      "AN ad nterupt f s ar igr t m:\n",
      "\n",
      "Thiny aleronth,\n",
      "MadPre?\n",
      "\n",
      "WISo myr f-NLIERor,\n",
      "Sb&y, wardsal thes ghesthidin cour ay aney Iry ts I&fr y ce.\n",
      "J\n"
     ]
    }
   ],
   "source": [
    "# Generate some text\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "out_idx = model.generate(idx, max_new_tokens=400)[0].tolist() # use [0] to get the first batch.\n",
    "print(decode(out_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9134e18",
   "metadata": {},
   "source": [
    "### The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2d91a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2  # batch, time, channels\n",
    "x: torch.Tensor = torch.randn(B, T, C).to(device)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78fc06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1: Using a for loop to calculate the mean of the previous time step.\n",
    "# We want to use previous time step to predict the next time step.\n",
    "# The easiest way to do this is to calculate the mean of the previous time step.\n",
    "# bow (bag of words) is a simple way to do this.\n",
    "x_bow: torch.Tensor = torch.zeros(\n",
    "    (B, T, C), device=device\n",
    ")\n",
    "for ib in range(B): # for each batch\n",
    "    for it in range(T): # for each time dimension\n",
    "        # x[ib, :it + 1]: shape (t, C)\n",
    "        # x_bow[ib, it]: shape (C,)\n",
    "        x_prev = x[ib, :it + 1] # (t, C)\n",
    "        x_bow[ib, it] = torch.mean(x_prev, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e73e8e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88c1846f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6631, -0.2513],\n",
       "        [ 0.1735, -0.0649],\n",
       "        [ 0.1685,  0.3348],\n",
       "        [-0.1621,  0.1765],\n",
       "        [-0.2312, -0.0436],\n",
       "        [-0.1015, -0.2855],\n",
       "        [-0.2593, -0.1630],\n",
       "        [-0.3015, -0.2293]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bow[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8472c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "------\n",
      "b=\n",
      "tensor([[3., 9.],\n",
      "        [8., 0.],\n",
      "        [3., 7.]], device='cuda:0')\n",
      "------\n",
      "c=\n",
      "tensor([[ 3.,  9.],\n",
      "        [11.,  9.],\n",
      "        [14., 16.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# lower triangular matrix can calculate the sum of the previous time step.\n",
    "a: torch.Tensor = torch.tril(torch.ones(3, 3, device=device))\n",
    "b: torch.Tensor = torch.randint(0, 10, (3, 2), device=device).float()\n",
    "c: torch.Tensor = a @ b\n",
    "print(f\"a=\\n{a}\")\n",
    "print(\"------\")\n",
    "print(f\"b=\\n{b}\")\n",
    "print(\"------\")\n",
    "print(f\"c=\\n{c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f422747b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]], device='cuda:0')\n",
      "------\n",
      "b=\n",
      "tensor([[3., 9.],\n",
      "        [8., 0.],\n",
      "        [3., 7.]], device='cuda:0')\n",
      "------\n",
      "c=\n",
      "tensor([[3.0000, 9.0000],\n",
      "        [5.5000, 4.5000],\n",
      "        [4.6667, 5.3333]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a: torch.Tensor = torch.tril(torch.ones(3, 3, device=device))\n",
    "a /= a.sum(dim=1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2), device=device).float()\n",
    "c: torch.Tensor = a @ b\n",
    "print(f\"a=\\n{a}\")\n",
    "print(\"------\")\n",
    "print(f\"b=\\n{b}\")\n",
    "print(\"------\")\n",
    "print(f\"c=\\n{c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97298dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 2: Using a lower triangular matrix to calculate the mean of the previous time step.\n",
    "# So the `x_bow: torch.Tensor = torch.zeros((B, T, C), device=device)` code above\n",
    "# can be replaced with:\n",
    "wei: torch.Tensor = torch.tril(torch.ones(T, T, device=device))\n",
    "wei /= wei.sum(dim=1, keepdim=True)\n",
    "x_bow2: torch.Tensor = wei @ x # (T, T) @ (B, T, C) = (B, T, T) @ (B, T, C) = (B, T, C)\n",
    "torch.allclose(x_bow, x_bow2, atol=1e-7)  # check if they are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1aa078e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei before softmax shape: torch.Size([8, 8])\n",
      "wei after softmax shape: torch.Size([8, 8]), x shape: torch.Size([4, 8, 2])\n",
      "x_bow and x_bow3 are equal: False, max_diff: 1.1920928955078125e-07\n",
      "x_bow2 and x_bow3 are equal: True, max_diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Version 3: use softmax to calculate the mean of the previous time step.\n",
    "tril: torch.Tensor = torch.tril(torch.ones(T, T, device=device))\n",
    "wei: torch.Tensor = torch.zeros((T, T), device=device)\n",
    "# fill all 0 (masked out) values with -inf\n",
    "wei = wei.masked_fill((tril == 0), float(\"-inf\"))\n",
    "print(f\"wei before softmax shape: {wei.shape}\")\n",
    "wei = wei.softmax(dim=-1)  # softmax of the row.\n",
    "print(f\"wei after softmax shape: {wei.shape}, x shape: {x.shape}\")\n",
    "\n",
    "x_bow3: torch.Tensor = wei @ x\n",
    "x_bow_x_bow3_equal: bool = torch.allclose(x_bow, x_bow3)\n",
    "x_bow2_x_bow3_equal: bool = torch.allclose(x_bow2, x_bow3)\n",
    "print(f\"x_bow and x_bow3 are equal: {x_bow_x_bow3_equal}, \"\n",
    "      f\"max_diff: {torch.max(torch.abs(x_bow - x_bow3))}\")\n",
    "print(f\"x_bow2 and x_bow3 are equal: {x_bow2_x_bow3_equal}, \"\n",
    "      f\"max_diff: {torch.max(torch.abs(x_bow2 - x_bow3))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b0bb59",
   "metadata": {},
   "source": [
    "### Single Head Self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b379aa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k shape: torch.Size([4, 8, 16]), q shape: torch.Size([4, 8, 16])\n",
      "wei shape: torch.Size([4, 8, 8])\n",
      "wei shape after softmax: torch.Size([4, 8, 8])\n",
      "out shape: torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "head_size: int = 16\n",
    "# Convert token to a key matrix.\n",
    "t_to_k: nn.Linear = nn.Linear(C, head_size, bias=False, device=x.device)\n",
    "# Convert token to a query matrix.\n",
    "t_to_q: nn.Linear = nn.Linear(C, head_size, bias=False, device=x.device)\n",
    "# Convert token to a value matrix.\n",
    "t_to_v: nn.Linear = nn.Linear(C, head_size, bias=False, device=x.device)\n",
    "\n",
    "k: torch.Tensor = t_to_k(x)  # (B, T, C) -> (B, T, head_size)\n",
    "q: torch.Tensor = t_to_q(x)  # (B, T, C) -> (B, T, head_size)\n",
    "v: torch.Tensor = t_to_v(x)  # (B, T, C) -> (B, T, head_size)\n",
    "print(f\"k shape: {k.shape}, q shape: {q.shape}\")\n",
    "# (B, T, head_size) @ (B, head_size, T) = (B, T, T)\n",
    "wei: torch.Tensor = q @ k.transpose(-2, -1)\n",
    "print(f\"wei shape: {wei.shape}\")\n",
    "\n",
    "tril: torch.Tensor = torch.tril(torch.ones(T, T, device=wei.device))\n",
    "# This is the decoder part, for encoder, we don't need to mask the future tokens.\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = wei.softmax(dim=-1)\n",
    "print(f\"wei shape after softmax: {wei.shape}\")\n",
    "out: torch.Tensor = wei @ v  # (B, T, T) @ (B, T, head_size) = (B, T, head_size)\n",
    "print(f\"out shape: {out.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c343ce0f",
   "metadata": {},
   "source": [
    "\"Scaled\" attention additional divides \"wei\" by 1 / sqrt(head_size). This makes it so when input Q, K are unit variance, the output is also unit variance. This is important for training stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd8e8625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k var: 1.0605725049972534\n",
      "q var: 1.0459474325180054\n",
      "wei var: 19.187782287597656\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size, device=device)\n",
    "q = torch.randn(B, T, head_size, device=device)\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "print(f\"k var: {k.var()}\")\n",
    "print(f\"q var: {q.var()}\")\n",
    "print(f\"wei var: {wei.var()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98025a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k var: 1.0497795343399048\n",
      "q var: 1.1699278354644775\n",
      "wei var: 1.2745065689086914\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size, device=device)\n",
    "q = torch.randn(B, T, head_size, device=device)\n",
    "wei = q @ k.transpose(-2, -1) * head_size ** -0.5\n",
    "print(f\"k var: {k.var()}\")\n",
    "print(f\"q var: {q.var()}\")\n",
    "print(f\"wei var: {wei.var()}\")\n",
    "\n",
    "# Note the \"14\" vs \"0.9b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1053c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
      "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1))\n",
    "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]) * 8, dim=-1))\n",
    "# Note that the 2nd one has peak value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52acbaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now investigate batch normalization.\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "\n",
    "    def __init__(\n",
    "        self, dim: int, eps: float = 1e-5, momentum: float = 0.1\n",
    "    ) -> None:\n",
    "        # Hyperparameters\n",
    "        self.eps: float = eps\n",
    "\n",
    "        # Parameters (trainable):\n",
    "        # gamma and beta are like the weight and bias in a linear layer\n",
    "        # gamma: scale parameter\n",
    "        self.gamma = torch.ones(dim).to(device)\n",
    "        # beta: shift parameter\n",
    "        self.beta = torch.zeros(dim).to(device)\n",
    "\n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_mean = x.mean(1, keepdim=True)\n",
    "        x_var = x.var(1, keepdim=True, unbiased=True)\n",
    "        x_norm = (x - x_mean) / torch.sqrt(x_var + self.eps)\n",
    "        x_norm_scaled: Final[torch.Tensor] = self.gamma * x_norm + self.beta\n",
    "\n",
    "        self.out: torch.Tensor = x_norm_scaled\n",
    "        return x_norm_scaled\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module: BatchNorm1d = BatchNorm1d(100)\n",
    "# batch size of 32, 100-dimensional vector\n",
    "x: torch.Tensor = torch.randn(32, 100, device=device)\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c848945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch mean: -0.16268089413642883\n",
      "batch std: 0.9686696529388428\n"
     ]
    }
   ],
   "source": [
    "# x[:, 0].mean(), x[:, 0].std()\n",
    "print(f\"batch mean: {x[:, 0].mean()}\")\n",
    "print(f\"batch std: {x[:, 0].std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f187bd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer mean: 1.3113021779531664e-08\n",
      "layer std: 0.9999955296516418\n"
     ]
    }
   ],
   "source": [
    "# x[0, :].mean(), x[0, :].std()\n",
    "print(f\"layer mean: {x[0, :].mean()}\")\n",
    "print(f\"layer std: {x[0, :].std()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Final\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset file and prepare the vocabulary.\n",
    "\n",
    "words: Final[list[str]] = open(\"names.txt\", 'r').read().splitlines()\n",
    "chars: Final[list[str]] = sorted(list(set(''.join(words))))\n",
    "stoi: Final[dict[str, int]] = {char: i + 1 for i, char in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos: Final[dict[int, str]] = {i: char for char, i in stoi.items()}\n",
    "char_cnt: Final[int] = len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset and the corresponding labels.\n",
    "\n",
    "def create_dataset(words: list[str], block_size: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    X: list[list[int]] = []\n",
    "    Y: list[int] = []\n",
    "    for word in words:\n",
    "        context: list[int] = [0] * block_size\n",
    "        for ix in word + '.':\n",
    "            X.append(context)\n",
    "            Y.append(stoi[ix])\n",
    "            context = context[1:] + [stoi[ix]]\n",
    "    X_t = torch.tensor(X)\n",
    "    Y_t = torch.tensor(Y)\n",
    "    print(X_t.shape, Y_t.shape)\n",
    "    return torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "device: Final[torch.device] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset for training, validation, and testing.\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "\n",
    "block_size: Final[int] = 3 # context length\n",
    "train_set_ratio: float = 0.8\n",
    "valid_set_ratio: float = 0.1\n",
    "test_set_ratio: float = 0.1\n",
    "\n",
    "n1: int = int(len(words) * train_set_ratio)\n",
    "n2: int = int(len(words) * (train_set_ratio + valid_set_ratio))\n",
    "\n",
    "X_train, Y_train = create_dataset(words[:n1], block_size)\n",
    "X_val, Y_val = create_dataset(words[n1:n2], block_size)\n",
    "X_test, Y_test = create_dataset(words[n2:], block_size)\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "Y_val = Y_val.to(device)\n",
    "X_test = X_test.to(device)\n",
    "Y_test = Y_test.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gradient checking functions.\n",
    "def cmp_grad(p_name: str, dp: torch.Tensor, p: torch.Tensor) -> None:\n",
    "    assert p.grad is not None, f\"Gradient for {p_name} is None\"\n",
    "    exact_eq: Final[bool] = bool(torch.all(dp == p.grad).item())\n",
    "    apprx_eq: Final[bool] = torch.allclose(dp, p.grad)\n",
    "    max_diff: Final[float] = (dp - p.grad).abs().max().item()\n",
    "    print(f\"{p_name:18s} | shape equal: {dp.shape == p.grad.shape} | \"\n",
    "          f\"exact equal: {str(exact_eq):5s} | \"\n",
    "          f\"approximate equal: {str(apprx_eq):5s} | max_diff: {max_diff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: 36837\n"
     ]
    }
   ],
   "source": [
    "# With batch normalization, we don't need to initialize the bias, but we\n",
    "# do it for calculating the gradient manually.\n",
    "# zero bias can mask the incorrect calculation of the gradient, so we\n",
    "# initialize it to a small value so that we can still check its value.\n",
    "\n",
    "num_neurons: Final[int] = 300\n",
    "embed_dim: Final[int] = 30\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((char_cnt, embed_dim), generator=g).to(device)\n",
    "# Layer 1\n",
    "W1 = torch.randn((block_size * embed_dim, num_neurons), generator=g).to(device) * (5 / 3) / ((embed_dim * block_size) ** 0.5)\n",
    "b1 = torch.randn(num_neurons, generator=g).to(device) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((num_neurons, char_cnt), generator=g).to(device) * 0.1\n",
    "b2 = torch.randn(char_cnt, generator=g).to(device) * 0.1\n",
    "\n",
    "# Batch normalization parameters\n",
    "bn_gain = torch.randn((1, num_neurons), generator=g).to(device) * 0.1 + 1.0\n",
    "bn_bias = torch.randn((1, num_neurons), generator=g).to(device) * 0.1\n",
    "bn_mean_running = torch.zeros((1, num_neurons)).to(device)\n",
    "bn_std_running = torch.ones((1, num_neurons)).to(device)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bn_gain, bn_bias]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "print(f\"parameters: {sum(p.nelement() for p in parameters)}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def calculate_loss(X_t: torch.Tensor, Y_t: torch.Tensor) -> torch.Tensor:\n",
    "    emb = C[X_t]\n",
    "    embcat = emb.view(-1, block_size * embed_dim)\n",
    "    h_preact = embcat @ W1 + b1\n",
    "    # Use the running mean/std.\n",
    "    h_preact_norm = (h_preact - bn_mean_running) / bn_std_running\n",
    "    h_preact = h_preact_norm * bn_gain + bn_bias\n",
    "    h = torch.tanh(h_preact)\n",
    "    logits = b2 + h @ W2\n",
    "    return F.cross_entropy(logits, Y_t)\n",
    "\n",
    "epochs: Final[int] = 200000\n",
    "loss = torch.tensor(1000.0)\n",
    "mini_batch_size: Final[int] = 128\n",
    "\n",
    "lossi: list[float] = []\n",
    "stepi = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.8407\n"
     ]
    }
   ],
   "source": [
    "# Mini-batch\n",
    "ix = torch.randint(0, X_train.shape[0], (mini_batch_size,))\n",
    "X_t_mini = X_train[ix]\n",
    "Y_t_mini = Y_train[ix]\n",
    "\n",
    "# Forward pass:\n",
    "\n",
    "# Get the embedding for the mini-batch.\n",
    "emb = C[X_t_mini]\n",
    "embcat = emb.view(-1, block_size * embed_dim)\n",
    "\n",
    "# Layer 1 starts.\n",
    "h_pre_bn = embcat @ W1 + b1\n",
    "\n",
    "# Batch normalization\n",
    "# dim=0 means that the rows are the ones to be eliminated:\n",
    "# adding all batch elements together.\n",
    "bn_mean_i = 1 / mini_batch_size * h_pre_bn.sum(dim=0, keepdim=True)\n",
    "bn_diff = h_pre_bn - bn_mean_i\n",
    "bn_diff_sq = bn_diff * bn_diff\n",
    "bn_var_i = 1 / (mini_batch_size - 1) * bn_diff_sq.sum(dim=0, keepdim=True)\n",
    "bn_std_i = (bn_var_i + 1e-5)**(0.5)\n",
    "bn_std_i_inverse = (bn_var_i + 1e-5)**(-0.5)\n",
    "bn_raw = bn_diff * bn_std_i_inverse\n",
    "h_pre_act = bn_raw * bn_gain + bn_bias\n",
    "\n",
    "# Nonlinear activation\n",
    "h = torch.tanh(h_pre_act)\n",
    "# Layer 1 ends.\n",
    "\n",
    "# Layer 2 starts.\n",
    "logits = h @ W2 + b2\n",
    "\n",
    "# Calculate cross entropy loss: loss = F.cross_entropy(logits, Y_t_mini)\n",
    "logit_maxes = logits.max(dim=1, keepdim=True).values\n",
    "normalized_logits = logits - logit_maxes # for numerical stability\n",
    "counts = normalized_logits.exp()\n",
    "counts_sum = counts.sum(dim=1, keepdim=True)\n",
    "counts_sum_inverse = counts_sum**(-1)\n",
    "probs = counts * counts_sum_inverse\n",
    "log_probs = probs.log()\n",
    "loss = -log_probs[torch.arange(mini_batch_size), Y_t_mini].mean()\n",
    "# Layer 2 ends.\n",
    "\n",
    "with torch.no_grad():\n",
    "    bn_mean_running = 0.999 * bn_mean_running + 0.001 * bn_mean_i\n",
    "    bn_std_running = 0.999 * bn_std_running + 0.001 * bn_std_i\n",
    "\n",
    "# Backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "# Retain the gradient for all the intermediate variables\n",
    "for t in [\n",
    "    log_probs, probs, counts_sum_inverse, counts_sum, counts,\n",
    "    normalized_logits, logit_maxes, logits, h, h_pre_act, bn_raw,\n",
    "    bn_std_i_inverse, bn_std_i, bn_var_i, bn_diff_sq, bn_diff, bn_mean_i,\n",
    "    h_pre_bn, embcat, emb\n",
    "]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "print(f\"loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 300]), torch.Size([1, 300]), torch.Size([1, 300]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_raw.shape, bn_gain.shape, bn_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 27]), torch.Size([128, 27]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.shape, probs.shape\n",
    "# loss = -(a + b + c) / 3\n",
    "# dloss/da = -1 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 27]), torch.Size([128, 1]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inverse.shape\n",
    "# c = a * b, but with tensors:\n",
    "# a[3x3] * b[3x1] ->\n",
    "# a11 * b11 + a12 * b21 + a13 * b31\n",
    "# a12 * b12 + a22 * b22 + a32 * b32\n",
    "# a13 * b13 + a23 * b23 + a33 * b33\n",
    "# c[3x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 27]), torch.Size([128, 1]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum.shape\n",
    "# a11 a12 a13 -> b1 (=sum(a11, a12, a13))\n",
    "# a21 a22 a23 -> b2 (=sum(a21, a22, a23))\n",
    "# a31 a32 a33 -> b3 (=sum(a31, a32, a33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 27])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 300]), torch.Size([1, 300]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_gain.shape, bn_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 300]), torch.Size([1, 300]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_diff.shape, bn_std_i_inverse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 300]), torch.Size([1, 300]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_std_i_inverse.shape, bn_var_i.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 300]), torch.Size([1, 300]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bn_var_i = 1 / (mini_batch_size - 1) * bn_diff_sq.sum(dim=0, keepdim=True)\n",
    "\n",
    "bn_diff_sq.shape, bn_var_i.shape\n",
    "\n",
    "# a11 a12 a13\n",
    "# a21 a22 a23\n",
    "# ->\n",
    "# b1  b2  b3\n",
    "# b1 = 1 / (mini_batch_size - 1) * (a11 + a21)\n",
    "# b2 = 1 / (mini_batch_size - 1) * (a12 + a22)\n",
    "# b3 = 1 / (mini_batch_size - 1) * (a13 + a23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 300]), torch.Size([128, 300]), torch.Size([1, 300]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_diff.shape, h_pre_bn.shape, bn_mean_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 300]), torch.Size([128, 300]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_mean_i.shape, h_pre_bn.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 90]), torch.Size([128, 3, 30]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embcat = emb.view(-1, block_size * embed_dim)\n",
    "embcat.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 30]) torch.Size([27, 30]) torch.Size([128, 3])\n",
      "tensor([[19,  7,  1],\n",
      "        [ 1, 13,  5],\n",
      "        [ 0,  0, 18],\n",
      "        [ 0, 12,  5],\n",
      "        [ 1,  8,  9]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# emb = C[X_t_mini]\n",
    "print(emb.shape, C.shape, X_t_mini.shape)\n",
    "print(X_t_mini[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check:\n",
      "log_probs          | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "probs              | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "counts_sum_inverse | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "counts_sum         | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "counts             | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "normalized_logits  | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "logit_maxes        | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "logits             | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "b2                 | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "W2                 | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "h                  | shape equal: True | exact equal: True  | approximate equal: True  | max_diff: 0.0\n",
      "h_pre_act          | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 2.3283064365386963e-10\n",
      "bn_raw             | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 2.3283064365386963e-10\n",
      "bn_gain            | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 1.862645149230957e-09\n",
      "bn_bias            | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 3.725290298461914e-09\n",
      "bn_std_i_inverse   | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 1.862645149230957e-09\n",
      "bn_var_i           | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 4.656612873077393e-10\n",
      "bn_diff_sq         | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 3.637978807091713e-12\n",
      "bn_diff            | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 2.3283064365386963e-10\n",
      "bn_mean_i          | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 1.862645149230957e-09\n",
      "h_pre_bn           | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 2.3283064365386963e-10\n",
      "embcat             | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 6.984919309616089e-10\n",
      "W1                 | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 7.450580596923828e-09\n",
      "b1                 | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 3.026798367500305e-09\n",
      "emb                | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 6.984919309616089e-10\n",
      "C                  | shape equal: True | exact equal: False | approximate equal: True  | max_diff: 8.381903171539307e-09\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually,\n",
    "# backpropagating through exactly all of the variables\n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "d_log_probs = torch.zeros_like(log_probs)\n",
    "d_log_probs[torch.arange(mini_batch_size), Y_t_mini] = -1 / mini_batch_size\n",
    "\n",
    "d_probs = (1.0 / probs) * d_log_probs\n",
    "\n",
    "d_counts_sum_inverse = (counts * d_probs).sum(dim=1, keepdim=True)\n",
    "\n",
    "# d_counts part1\n",
    "d_counts = counts_sum_inverse * d_probs\n",
    "\n",
    "d_counts_sum = (-1) * (counts_sum**(-2)) * d_counts_sum_inverse\n",
    "\n",
    "# d_counts part2\n",
    "# This can also be simplified to: d_counts += d_counts_sum\n",
    "# Because `d_counts`'s shape is already the same as `counts`.\n",
    "# We will do broadcasting. `torch.ones_like(counts)` is unnecessary.\n",
    "d_counts += torch.ones_like(counts) * d_counts_sum\n",
    "\n",
    "# `normalized_logits.exp()` is already `counts`.\n",
    "d_normalized_logits = counts * d_counts\n",
    "\n",
    "# d_logits part1\n",
    "d_logits = d_normalized_logits.clone()\n",
    "\n",
    "d_logit_maxes = -d_logits.sum(dim=1, keepdim=True)\n",
    "\n",
    "# d_logits part2\n",
    "d_logits += F.one_hot(logits.argmax(dim=1), num_classes=logits.shape[1]) * d_logit_maxes\n",
    "\n",
    "d_b2 = d_logits.sum(dim=0)\n",
    "d_W2 = h.T @ d_logits\n",
    "d_h = d_logits @ W2.T\n",
    "\n",
    "d_h_pre_act = (1.0 - h**2) * d_h\n",
    "\n",
    "d_bn_raw = bn_gain * d_h_pre_act # Broadcast happens here.\n",
    "d_bn_gain = (bn_raw * d_h_pre_act).sum(dim=0, keepdim=True)\n",
    "d_bn_bias = d_h_pre_act.sum(dim=0, keepdim=True)\n",
    "\n",
    "d_bn_diff = bn_std_i_inverse * d_bn_raw # Broadcast happens here.\n",
    "d_bn_std_i_inverse = (bn_diff * d_bn_raw).sum(dim=0, keepdim=True)\n",
    "\n",
    "d_bn_var_i = (-(0.5) * (bn_var_i + 1e-5)**(-1.5)) * d_bn_std_i_inverse\n",
    "\n",
    "d_bn_diff_sq = (1.0 / (mini_batch_size - 1)) * torch.ones_like(bn_diff_sq) * d_bn_var_i\n",
    "\n",
    "d_bn_diff += 2.0 * bn_diff * d_bn_diff_sq\n",
    "\n",
    "d_bn_mean_i = (-1.0) * d_bn_diff.sum(dim=0, keepdim=True)\n",
    "d_h_pre_bn = d_bn_diff.clone()\n",
    "\n",
    "d_h_pre_bn += (1.0 / mini_batch_size) * torch.ones_like(h_pre_bn) * d_bn_mean_i\n",
    "\n",
    "d_embcat = d_h_pre_bn @ W1.T\n",
    "d_W1 = embcat.T @ d_h_pre_bn\n",
    "d_b1 = d_h_pre_bn.sum(dim=0)\n",
    "\n",
    "d_emb = d_embcat.view(emb.shape)\n",
    "\n",
    "d_C = torch.zeros_like(C)\n",
    "for i in range(X_t_mini.shape[0]):\n",
    "    for j in range(X_t_mini.shape[1]):\n",
    "        k = X_t_mini[i, j]\n",
    "        d_C[k] += d_emb[i, j]\n",
    "\n",
    "# and checking the gradients with cmp_grad.\n",
    "print(\"Gradient check:\")\n",
    "cmp_grad(\"log_probs\", d_log_probs, log_probs)\n",
    "cmp_grad(\"probs\", d_probs, probs)\n",
    "cmp_grad(\"counts_sum_inverse\", d_counts_sum_inverse, counts_sum_inverse)\n",
    "cmp_grad(\"counts_sum\", d_counts_sum, counts_sum)\n",
    "cmp_grad(\"counts\", d_counts, counts)\n",
    "cmp_grad(\"normalized_logits\", d_normalized_logits, normalized_logits)\n",
    "cmp_grad(\"logit_maxes\", d_logit_maxes, logit_maxes)\n",
    "cmp_grad(\"logits\", d_logits, logits)\n",
    "cmp_grad(\"b2\", d_b2, b2)\n",
    "cmp_grad(\"W2\", d_W2, W2)\n",
    "cmp_grad(\"h\", d_h, h)\n",
    "cmp_grad(\"h_pre_act\", d_h_pre_act, h_pre_act)\n",
    "cmp_grad(\"bn_raw\", d_bn_raw, bn_raw)\n",
    "cmp_grad(\"bn_gain\", d_bn_gain, bn_gain)\n",
    "cmp_grad(\"bn_bias\", d_bn_bias, bn_bias)\n",
    "cmp_grad(\"bn_std_i_inverse\", d_bn_std_i_inverse, bn_std_i_inverse)\n",
    "cmp_grad(\"bn_var_i\", d_bn_var_i, bn_var_i)\n",
    "cmp_grad(\"bn_diff_sq\", d_bn_diff_sq, bn_diff_sq)\n",
    "cmp_grad(\"bn_diff\", d_bn_diff, bn_diff)\n",
    "cmp_grad(\"bn_mean_i\", d_bn_mean_i, bn_mean_i)\n",
    "cmp_grad(\"h_pre_bn\", d_h_pre_bn, h_pre_bn)\n",
    "cmp_grad(\"embcat\", d_embcat, embcat)\n",
    "cmp_grad(\"W1\", d_W1, W1)\n",
    "cmp_grad(\"b1\", d_b1, b1)\n",
    "cmp_grad(\"emb\", d_emb, emb)\n",
    "cmp_grad(\"C\", d_C, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 27]), torch.Size([128, 27]), torch.Size([128, 1]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_normalized_logits.shape, logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_logits: torch.Size([128, 27])\n",
      "h: torch.Size([128, 300])\n",
      "W2: torch.Size([300, 27])\n",
      "b2: torch.Size([27])\n"
     ]
    }
   ],
   "source": [
    "print(f\"d_logits: {d_logits.shape}\\nh: {h.shape}\\nW2: {W2.shape}\\nb2: {b2.shape}\")\n",
    "# Given logits = h @ W2 + b2\n",
    "# We know that:\n",
    "# d_h ([128, 300]) must be calculated with logits([128, 27]) and W2([300, 27])\n",
    "# So we need to get [128, 300] from [128, 27] and [300, 27]\n",
    "# which is [128, 27] @ [27, 300]\n",
    "# which is [128, 27] @ [300, 27].T\n",
    "# so\n",
    "# d_h = d_logits @ W2.T\n",
    "\n",
    "# We know that:\n",
    "# d_W2 ([300, 27]) must be calculated with h([128, 300]) and d_logits([128, 27])\n",
    "# So we need to get [300, 27] from [128, 300] and [128, 27]\n",
    "# which is [128, 300].T @ [128, 27]\n",
    "# so\n",
    "# d_W2 = h.T @ d_logits\n",
    "\n",
    "# We know that:\n",
    "# d_b2 ([27]) must be calculated with d_logits([128, 27])\n",
    "# So we need to get [27] from [128, 27]\n",
    "# which is [128, 27].sum(dim=0)\n",
    "# so\n",
    "# d_b2 = d_logits.sum(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Derivative Calculation](Matrix_Derivative.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 300])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_h_pre_act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 300]),\n",
       " torch.Size([128, 90]),\n",
       " torch.Size([90, 300]),\n",
       " torch.Size([300]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_h_pre_bn.shape, embcat.shape, W1.shape, b1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 300]), torch.Size([128, 300]), torch.Size([1, 300]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_bn_diff.shape, h_pre_bn.shape, bn_mean_i.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300]), torch.Size([1, 300]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_bn_mean_i.shape, bn_mean_i.grad.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
